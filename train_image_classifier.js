const tf = require("@tensorflow/tfjs");
const fs = require("fs").promises;
const path = require("path");
const { createCanvas, loadImage } = require("canvas");

/**
 * Configuration constants for the image classification model.
 * @constant {number} IMAGE_SIZE - The size to which images are resized (width and height).
 * @constant {number} CLASSIFICATION_THRESHOLD - Threshold for binary classification (0 to 1).
 *
 */
const CONFIG = {
  IMAGE_SIZE: 128,
  CLASSIFICATION_THRESHOLD: 0.6,
};

/**
 * Loads and preprocesses images from a directory.
 * @param {string} dirPath - Path to the directory containing images.
 * @param {number} label - Label for the images (1 for correct, 0 for incorrect).
 * @returns {Promise<Array>} Array of objects containing image tensors, labels, and file names.
 */
async function loadImagesFromDir(dirPath, label) {
  try {
    const files = await fs.readdir(dirPath);
    const images = [];

    console.log(`üìÇ Loading images from ${dirPath}...`);

    for (const file of files) {
      const imgPath = path.join(dirPath, file);
      try {
        const img = await loadImage(imgPath);
        const canvas = createCanvas(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE);
        const ctx = canvas.getContext("2d");
        ctx.drawImage(img, 0, 0, CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE);
        const imageTensor = tf.browser
          .fromPixels(canvas)
          .toFloat()
          .div(tf.scalar(255.0))
          .reshape([CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE, 3]);
        images.push({ tensor: imageTensor, label, file });
        console.log(`‚úÖ Loaded ${imgPath}`);
      } catch (err) {
        console.error(`‚ùå Failed to load ${imgPath}: ${err.message}`);
      }
    }

    console.log(`‚úÖ Loaded ${images.length} images from ${dirPath}`);
    return images;
  } catch (err) {
    console.error(`‚ùå Error reading directory ${dirPath}: ${err.message}`);
    throw err;
  }
}

/**
 * Loads and prepares the dataset for training.
 * @returns {Promise<Object>} Dataset containing input tensors (xs), labels (ys), and samples.
 */
async function loadDataset() {
  console.log("üß™ Loading dataset...");
  try {
    const correct = await loadImagesFromDir("./data/correct", 1);
    const incorrect = await loadImagesFromDir("./data/incorrect", 0);
    const all = correct.concat(incorrect);
    console.log(`üìä Total samples: ${all.length}`);

    const xs = tf.stack(all.map((i) => i.tensor));
    const ys = tf.tensor(all.map((i) => i.label)).reshape([all.length, 1]);

    console.log("‚úÖ Dataset tensors prepared.");
    return { xs, ys, samples: all };
  } catch (err) {
    console.error("‚ùå Failed to load dataset:", err.message);
    throw err;
  }
}

/**
 * Creates and compiles a convolutional neural network model.
 * @returns {tf.Sequential} Compiled TensorFlow.js model.
 */
function createModel() {
  console.log("‚öôÔ∏è Creating model...");
  const model = tf.sequential();

  model.add(
    tf.layers.conv2d({
      inputShape: [CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE, 3],
      filters: 16,
      kernelSize: 3,
      activation: "relu",
    })
  );
  model.add(tf.layers.maxPooling2d({ poolSize: 2 }));
  model.add(
    tf.layers.conv2d({ filters: 32, kernelSize: 3, activation: "relu" })
  );
  model.add(tf.layers.maxPooling2d({ poolSize: 2 }));
  model.add(tf.layers.flatten());
  model.add(tf.layers.dropout({ rate: 0.3 }));
  model.add(tf.layers.dense({ units: 64, activation: "relu" }));
  model.add(tf.layers.dropout({ rate: 0.2 }));
  model.add(tf.layers.dense({ units: 1, activation: "sigmoid" }));

  model.compile({
    loss: "binaryCrossentropy",
    optimizer: tf.train.adam(0.001),
    metrics: ["accuracy"],
  });

  console.log("‚úÖ Model ready.");
  return model;
}

/**
 * Evaluates the model on provided samples.
 * @param {tf.Sequential} model - The trained model.
 * @param {Array} samples - Array of sample objects with tensors, labels, and file names.
 */
async function evaluateModel(model, samples) {
  console.log("\nüß† Evaluating model on training samples:");
  for (const sample of samples) {
    const input = sample.tensor.reshape([
      1,
      CONFIG.IMAGE_SIZE,
      CONFIG.IMAGE_SIZE,
      3,
    ]);
    const prediction = model.predict(input);
    const score = (await prediction.data())[0];

    const expected = sample.label === 1 ? "CORRECT" : "INCORRECT";
    const predicted =
      score >= CONFIG.CLASSIFICATION_THRESHOLD ? "CORRECT ‚úÖ" : "INCORRECT ‚ùå";

    console.log(
      `üì∑ ${sample.file}: score=${score.toFixed(
        4
      )} ‚Üí expected=${expected} ‚Üí predicted=${predicted}`
    );

    input.dispose();
    prediction.dispose();
  }
}

/**
 * Saves the model to disk in JSON format with binary weights.
 * @param {tf.Sequential} model - The model to save.
 */
async function saveModel(model) {
  try {
    console.log("üíæ Saving model...");
    await model.save(
      tf.io.withSaveHandler(async (data) => {
        const modelJson = JSON.stringify({
          modelTopology: data.modelTopology,
          format: "layers-model",
          generatedBy: "TensorFlow.js",
          convertedBy: null,
        });

        await fs.mkdir("./model", { recursive: true });
        await fs.writeFile("./model/model.json", modelJson);
        await fs.writeFile("./model/weights.bin", Buffer.from(data.weightData));

        console.log("‚úÖ Model saved to ./model");
        return {
          modelArtifactsInfo: {
            dateSaved: new Date(),
            modelTopologyType: "JSON",
            weightDataBytes: data.weightData.byteLength,
          },
        };
      })
    );
  } catch (err) {
    console.error("‚ùå Failed to save model:", err.message);
    throw err;
  }
}

/**
 * Main function to orchestrate dataset loading, model training, and evaluation.
 */
async function main() {
  try {
    const { xs, ys, samples } = await loadDataset();
    const model = createModel();

    console.log("üöÄ Starting training...");
    await model.fit(xs, ys, {
      // epochs: 20,
      // batchSize: 4,
      // validationSplit: 0.2,
      epochs: 2,
      batchSize: 8,
      validationSplit: 0.2,
      callbacks: {
        onEpochEnd: (epoch, logs) => {
          console.log(
            `üìà Epoch ${epoch + 1}: loss=${logs.loss.toFixed(
              4
            )}, acc=${logs.acc.toFixed(4)}, val_acc=${logs.val_acc?.toFixed(4)}`
          );
        },
      },
    });

    await evaluateModel(model, samples);
    await saveModel(model);

    // Clean up tensors
    xs.dispose();
    ys.dispose();
    samples.forEach((sample) => sample.tensor.dispose());
    console.log("üßπ Cleaned up tensors.");
  } catch (err) {
    console.error("‚ùå Fatal error:", err.message);
    process.exit(1);
  }
}

// Execute main function
// main();
